# Attribute Disclosure

## $k$-anonimity

**k-anonymity è vulnerabile** ad alcuni attacchi. Il classico è quello dell'informazione sensibile a cui è associata. 

### Attacco 1: Omogeneità dei valori di attributi sensibili

Se, per esempio, ho k-occorrenze di una n-upla di QI ma le informazioni associate (tipo la malattia) sono tutte uguali, allora posso comunque inferire con esattezza che una certa persona abbia una malattia.

- conoscenza: presenza in tabella

### Attacco 2: Conoscenza a priori (background knowledge)

Chi conosce o chi può accedere a informazioni extra riguardo una persona, può dedurre altro. Tipo: una ragazza corre ogni giorno 2 ore al giorno, non può avere malattie respiratorie

- conoscenza: presenza in tabella, abitudini/comportamenti

# $l$-diversity

Un blocco $q$-block, ovvero delle tuple con degli stessi valori di attributi $QI$ è considerato $l$-diverso se ci sono almeno $l$-diversi valori negli attributi sensibili

- **concetto di entropia**: $q$-block è $l$-diverso se la rimozione di un dato sensibile rimane ($l$-1)-diverso, quindi resistente di grado $l$

Un avversario dunque deve eliminare almeno $l$-1 possibili valori per inferire il valore del rispondente target

**Una tabella è $l$-diversa se tutti i suoi $q$-blocchi sono $l$-diversi**

- non è più possibile attacco per omogeneità

- l'attacco per conoscenza a priori è più difficile

Ogni algoritmo per il $k$-anonymity può essere esteso per forzare la proprietà di $l$-diversity.

**$l$-diversity è monotona** rispetto alle gerarchia di generalizzazione, per cui il kernel del software non si cambia

**ATTENZIONE: $l$-diversity è vulnerabile agli attacchi sulla distribuzione dei valori nei $q$-blocks (SIMILARITY e SKEWNESS)**

## Attacco 1: Skewness

Occorre quando la distribuzione dei valori sensibili associata a un $q$-blocco è diversa dalla distribuzione attesa, ovvero la distribuzione reale della popolazione

- esempio: il 20% della popolazione ha il diabete. Il 75% delle tuple nel $q$-blocco ha il diabete. Cosa vuol dire? Che se prima del rilascio c'era un 20% di probabilita che una persona avesse il diabete, sapendo che la persona è nel rilascio, la probabilità sale al 75%.

## Attacco 2: Similarity

Occorre quando in un $q$-blocco hanno valori diversi ma che sono semanticamente simili negli attributi sensibili. Esempio: se so che sei in una tabella, e la tabella pubblica l'organo preso dal tumore, posso inferire che hai un tumore.

# Difesa: $t$-closeness

Un $q$-blocco rispetta la $t$-closeness se la distanza della distribuzione dei valori degli attributi sensibili in tabella dalla distribuzione dei valori nella popolazione (mondo reale) è minore di $t$

Una tabella rispetta $t$-closeness se tutti i suoi $q$-blocchi rispettano $t$-closeness

E' monotonica rispetto alle gerarchie di generalizzazione

Può essere estesa da un algoritmo di k-anon

# Modello dell'osservatore

Un osservatore può avere o può accedere a informazioni per fare inferenze su informazioni sensibili. Difatti può conoscere

- l'individuo

- informazioni di altri individi simili o intorno a lui

- informazioni identiche per l'intera famiglia (dove abita, cose genetiche ecc...)

## Rilasci multipli dei dati

Alcuni dati che cambiano di frequente vengono pubblicati su basi regolari ogni tot. Possono causare un leak di informazioni se l'osservatore trova correlazione tra i vari rilasci

**I rilasci multipli (longitudinali) NON POSSONO ESSERE INDIPENDENTI**

Bisogna assicurarsi che questi rilasci non creino intersezioni soggette ad attacco

## $m$-invariance

Affronta il problema dei rilasci multipli.

Una sequenza di tabelle $T_1, ..., Tn$ soddisfano la m-invarianza se e solo se

- ogni classe di equivalenza include almeno m tuple

- nessun valore sensibile appare più volte in ogni classe di equivalenza

- per ogni tupla $t$, la classe di equivalenza a cui appartiene $t$ sono caratterizzate dallo **stesso insieme di valori sensibili**

In questo modo **la correlazione tra tuple di $T_1, ..., Tn$ non permette di associare meno di m-differenti valori sensibili a ogni rispondente**

## Conclusioni

$k$-anonymity, $l$-diversity e $t$-closeness si basano sull'assunzione che non è presente in tutti gli scenari. Tipo:

- più tuple per rispondente

- rilascio multiplo di tabelle con dipendenze funzionali

- più quasi-identifiers

- quasi-identifiers non definiti

- rilasci di uno stream di dati

- preferenze privacy granulari e dettagliate

### $k$-anonymity extended

Può essere applicato a tante cose, come data mining, social networks, location based...

#### $k$-anonymity in social networks

- Un vertice v è k-anonimo se esistono almeno altri k-1 vertici tali per cui i sottografi indotti dai vicini di v e i vertici v k-1 sono isomorfi

- Un grafo G è k-anonimo se tutti i vertici in G sono k-anonimi

- Se un grafo è k-anonimo allora ogni vertice può essere re-identificato in G con confidenza 1 su k

#### $k$-anonymity in data mining

#### $k$-anonymity in location-based services
