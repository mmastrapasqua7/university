# k-minimal computation

è un problema NP difficile, perchè dovresti vedere ogni combinazione possibile. Tutti gli algoritmi esatti hanno tempo esponenziale legalo al numero di attributi che compongono il quasi-identificatore.

La complessità è esponenziale nell'input, ovvero $n$ di attributi che compongono il $QI$

- Quando la cardinalità degli attributi quasi identificatori $|QI|$ è piccola in rapporto al numero di tuple (n) nella tabella, questi algoritmi sono pratici

## Algoritmi ESATTI per k-minimal anon (AG_TS & AG_)

Se guardo i reticoli del Distance Vector, voglio trovare il vettore che mi da k-anon e che sia minimale, ovvero che non sopprima più di quel che voglio. 

1. Se il vettore mi da k-anon, controllo se ho k-anon a livello sotto

2. Se non ho k-anon ai livelli sotto, allora è minimale

#### k-minimal locally

Parto dal basso e seguo un solo cammino. La prima soluzione che trovo è **k-minimal locally**, ovvero è minimale localmente al cammino. Una volta trovata la prima **k-minimal locally**, controllo che tutte le gerarchie che domina non soddisfino anche loro k-anonimity. Se lo fanno, allora rifaccio la cosa finchè non rimango con solo una soluzione che è **k-minimal**. 

**ATTENZIONE**: POSSONO ESISTERE PIU' SOLUZIONI VALIDE AL PROBLEMA, DIPENDE SOLAMENTE DALL'ATTRIBUTO CHE VOGLIO GENERALIZZARE DI MENO, MA POSSONO ESISTERE PIU' DI UNA SOLUZIONE.

#### Assunzione monotonicità

Commento: devo stare attento a come generalizzare, perchè da questo può dipendere la mia gerarchia di generalizzazione e spezzare l'albero. Esempio, un gruppetto di [70, 80) anni se lo spezzo male in [65, 75) e [75, 85) rompo l'assunzione e l'albero va a male

### Algoritmo 1: Binary Search (dicotomica)

**ASSUNZIONE MONOTONICITA'**

Sulla base del k-minimal locally applico l'algoritmo di ricerca binaria. Guardo la mia gerarchia di generalizzazione e taglio in due. A metà cerco se esiste una soluzione. Se si ripeto l'algoritmo nella metà bassa, se non esiste salgo nella metà sopra. **attenzione: mi trova solo 1 soluzione.**

Per ridurre il costo computazionale adotta una matrice di vettori distanza, che serve per capire quando c'è una soluzione.

### Algoritmo 2: K-Optimize

Non assume monotonicità. Prendo gli attributi del $QI$ e li ordino, poi ordino i valori dei domini. A ogni valore, ordinato, gli assegno un numero. Metto insieme le cose come mi viene meglio. **Metto insieme cose adiacenti, vicine**. 

Costruisco un albero di enumerazione di insiemi. La radice sarà vuota. Ogni nodo avrà un costo che si traduce nel costo di generalizzazione e soppressione dell'anonimizzazione rappresentato dal nodo.

**Ogni tupla è associata a un costo che riflette la perdita di informazione associata alla generalizzazione e/o soppressione**

1. Parto dalla radice e vado giù con depth-first

2. Se quel nodo non è una soluzione, allora l'intero albero sotto (figli) non è una soluzione. Perchè? Perchè più vado in basso e più li separo, più il k di anonymity si abbassa (**pruning**)

### Algoritmo 3: Incognito

Per controllare il k-anonymity di una tupla su $QI$, mi basta controllare iterativamente che sottoinsiemi sempre più grandi di attributi soddisfino k-anon. **Condizione necessaria (non sufficiente) per k-anon è che ogni attributo QI sia k-anon, ovvero abbia k-valori**.

1. Parto considerando gli attributi singoli (A0, B0... Z0) e scarto tutte quelle generalizzazioni che da sole non soddisfano k-anon, tipo posso rimanere con (A0, B0 e Z1). Fatto ciò butto via dalla mia gerarchia tutte quelle scartate (tipo Z0)

2. Poi considero a coppie le generalizzazioni rimaste e provo k-anon per tutte le combinazioni di tuple a coppie. Rifaccio la stessa cosa: Butto via dalla gerarchia i nodi che contengono quelle coppie scartate (esempio tutte quelle che contengono A0 e Z0)

3. Considero le triple rimaste...

4. ...

5. L'iterazione $QI$ ritorna il risultato finale

### Algoritmi EURISTICI

Non ti do la soluzione precisa ma almeno produco una soluzione in tempi non esponenziali

## Algoritmi ESATTI per k-minimal anon (\_CS e CG\_)

### Algoritmo 1: Mondrian multidimensionale (partizionamento)

1. Ogni attributo in $QI$ rappresenta una dimensione

2. Ogni tupla della tabella di partenza rappresenta un punto nello spazio multidimensionale

3. Ogni tupla con gli stessi valori di attributi in $QI$ sono rappresentati da un numero al posto di un punto che rappresenta il numero di occorrenze

4. Scelgo una dimensione e la partiziono cercando di fare gruppi di almeni k occorrenze. Lo faccio per ogni dimensione e iterativamente finchè non ottengo valori singoli. Tipo: k-anon di 3, allora devo avere almeno 3 occorrenze per ogni partizione

5. Tutti i punti nella regione minima, ovvero partizione minima, vengono generalizzati a un unico valore. Le tuple corrispondenti vengono sostituite dalla generalizzazione computata

**E' molto flessibile** riguardo il tipo di attributi, il numero, le strategie di generalizzazione e di partizionamento e diverse metriche.

### Algoritmi EURISTICI di approssimazione

# K-anonymity: rivisitazione

**Richiesta principale: ogni combinazione di quasi-identifiers deve riportare ad almeno k rispondenti**

Quando la generalizzazione è fatta a livello di attributo (**AG**), questo è equivalente a richiedere che ogni n-upla di $QI$ ha almeno k occorrenze

Ma quando la generalizzazione è fatta a livello di cella (**CG**) l'esistenza di almeno k-occorrenze è **sufficiente** ma **non necessaria**. Si può espirmere una nuova formulazione:

- Per ogni n-upla $pt$ di $QI$ in PT ci sono almeno k-tuple in GT (tabella generalizzata) che contengono una sequenza di valori che generalizzano $pt$

- Per ogni n-upla $t$ di $QI$ in GT ci sono almeno k-tuple in PT che contengono una sequenza di valori per cui $t$ è la sua generalizzazione
