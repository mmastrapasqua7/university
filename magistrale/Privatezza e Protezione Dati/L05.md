# Disseminazione di dati in tabelle di magnitudo/grandezza

La distribuzione di questi valori è facile da intuire. Quello che si può fare è **prevenire una precisa stima dei valori outliers**. In questo caso il sample non protegge, servono altre tecniche.

## Soppressione: regole

Determinano se una cella potrebbe rivelare informazioni riguardo un individuo rispondente. Devo capire se un valore è sensibile se è possibile inferire qualcosa

- **p-percent**

- **pq**

- **(n, k)**

Questi metodi sono usati per identificare celle sensibili verificano la **difficoltà di un rispondente di stimare i valori riportati di altri rispondenti con troppa precisione**

### p-percent rule

Hai un problema se l'osservatore può stimare il valore troppo vicino.

**Una cella è considerata sensibile se il valore inferiore superiore del valore della cella corrispondente possono essere stimati entro una certa soglia $p$**

$$
\sum_{i=c+2}^{N} x_i \ge \frac{p}{100} x_1
$$

- $c$: dimensione della coalizione di rispondenti interessati a sapere dati di un altro rispondente (assunzione)

- $c+2$: quello che la coalizione non conosce: tutti tranne la coalizione e il valore alto che vogliono inferire

- $x_1, ..., x_N$ valore dei rispondenti in ordine decrescente

- $x_1$ è il valore più grande

Chi può inferire contribuisce alla statistica.

- esempio: quelli che guadagnano di più inferiscono di più degli altri nel calcolo della statistica. Se una coalizione di 3 persone vuole inferire il valore più alto, si unisce e calcola una probabilità

### pq rule

Variante del p-percent. Assunzione che non solo c'è coalizone, ma c'è anche **conoscenza pregressa**. In questo caso, $q$ rappresenta l'errore nella stima prima della pubblicazione della cella

$$
\frac{q}{100} \sum_{i=c+2}^{N} x_i \ge \frac{p}{100} x_1
$$

- esempio: facendo finta di un $q$ di 80%, ovvero quanto accuratamente si può stimare un valore prima della pubblicazione. (Se $q$ = 100, ovvero incertezza 100%, allora è equivalente alla p-percent)

### (n, k) rule

Se un piccolo numero di rispondenti $n$ contribuisce a una grande percentuale $k$ del totale (20-80 rule), la cella è considerata sensibile. Gli altri possono fare inferenza sugli $n$.

- esempio: se sul totale di 250k bastano 2 persone che coprono 180k, allora quei 2 rappresentano ben il 72% del totale dei guadagni. Assumendo $(n, k)$ = (2, 70), allora è sensibile (72% > k = 70)

### Soppressione secondaria

Perchè ci vuole soppressione secondaria? Per evitare di ricalcolare le celle sensibili soppresse in partenza. Bisogna stare attenti.

#### Information loss

La selezione di celle complementari deve risultare nella minima perdita di informazione. Altrimenti è tutto inutile.

# Microdati

Carrellata di possibili modi di sanitizzare i dati. Non esiste un dataset anonimo, ma de-identificato, ovvero che tolgo l'identità. Ovviamente devo tener d'occhio i $QI$

- Posso diminuire l'informazione

- Posso cambiare i dati in un modo che sia più vicino possibile

## Tecniche di protezione nella pubblicazione

Quello che devo fare è

- includere solo un campione della popolazione

- rimuovere gli identificatori

- limitare i dettagli geografici

- limitare il numero di attributi/variabili

#### Limitare dati geografici

Se ho dati geografici devo stare attento di non avere aree che si riferiscono a meno di tot persone (k-anon geografico). In generale si riferisce ad **altre informazioni contestuali**

- **tecniche di mascheramento**: sanitizzare i dati

- generazione di dati sintetici
  
  quando devo rilasciare dei dati

### Tecniche di mascheramento

- **non-perturbative** (generalizzazione, soppressione)

- **perturbative**

#### Non-Perturbativo

##### Sampling

La protezione della tabella di microdati è ottenuta usando un campione, sample, di quella di partenza. In questo modo c'è incertezza riguardo la presenza o assenza di un certo individuo

##### Local suppression

Sopprimo il valore di un attributo limitando i rischi di analisi. Cancello il valore di certi attributi che potrebbero contribuire significativamente al rischio di leak della tupla

##### Global recoding

Invece di pubblicare qualcosa di specifico, uso un attributo qualitativo: stipendio, invece che la quantità metto basso, medio, alto in base a fasce di guadagno (<24k, <64k, ...)

##### Top-coding e Bottom-coding

Metto un limite superiore/inferiore rispetto ai valori che pubblico. I valori sopra/sotto quel certo limite dico che sono superiori e non li pubblico in valore.

- top-coding: se un valore è sopra una certa soglia, dico che è sopra una certa soglia

- bottom-coding: stessa cosa quando è sotto una certa soglia, dico che è sotto quella certa soglia

Può essere applicato per categorie di attributi lineari ordinabili e/o dati continui

##### Generalizzazione

Proprietà **monotonicità**: andando a generalizzare, più generalizzo e più gli insieme diventano grossi. Ricorda: inserendo gli intervalli si rompe la monotonicità per via dell'assunzione sull'albero: la monotonicità ci dice che più andiamo in alto e più l'insieme si allarga. Con gli intervalli può diminuire

#### Perturbative

**Devo preoccuparmi dell'effetto che il rumore ha**

##### Random noise

Perturba un attributo sensibile aggiungendogli o moltiplicandolo con una variabile random con una distribuzione data.

##### Swapping

Tecnica più invadente. Esempio: scambio (holidays, income) per tuple con lo stesso (sex, marStat)

Con questa tecnica non posso considerare i dati sanitizzati, sporca troppo rispetto alle altre

##### Micro-aggregation (blurring)

Raggruppo individui in piccoli gruppi di dimensione fissa

Invece di pubblicare i valori degli individui, faccio una microstatistica sul gruppetto. E' come aver fatto tot cluster piccoli, clusterini

Non vado a pubblicare i valori specifici, ma pubblico solamente la microstatistica (esempio la media)

### Tecniche sintetiche

**I dati sintetici devono presentare le stesse qualità delle analisi statistiche dei dati originali**

I pro di questa tecnica è che nessuna delle tuple porta ai rispondenti originali, non può avere reidentificazione.
